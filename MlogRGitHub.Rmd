---
title: "FHLogReg2"
author: "Nionella Bt Stephen Sampil"
date: "2023-12-18"
output: 
  rmdformats::readthedown
---

# Introduction

## Group Members

![](DSC_1199.JPG)

Nionella binti Stephen Sampil

Wan Nor Syafiqah binti Wan Salleh

Nur Hafizah binti Sukeri

Farah Munirah binti Mior Mazlan

Zahid bin Zulkifli

Ahmad Firdaus bin Mohamed

## Dataset

This dataset is publically available on the Kaggle website, it is an ongoing cardiovascular study on residents of the town of Framingham, Massachusetts. The dataset provides the patient's information. It includes over 4000 records and 15 attributes.

Variables:

Each attribute is a potential risk factor. There are both demographic, behavioral and medical risk factors.

**Demographic:**

-   Sex: male or female(Nominal)

-   Age: Age of the patient;(Continuous )

**Behavioral**

-   Current Smoker: whether or not the patient is a current smoker (Categorical/Nominal)

-   Cigs Per Day: the number of cigarettes that the person smoked on average in one day.(continuous)

**Medical( history)**

-   BP Meds: whether or not the patient was on blood pressure medication (Categorical/Nominal)

-   Prevalent Stroke: whether or not the patient had previously had a stroke (Categorical/Nominal)

-   Prevalent Hyp: whether or not the patient was hypertensive (Categorical/Nominal)

-   Diabetes: whether or not the patient had diabetes (Categorical/Nominal)

**Medical(current)**

-   Tot Chol: total cholesterol level (Continuous)

-   Sys BP: systolic blood pressure (Continuous)

-   Dia BP: diastolic blood pressure (Continuous)

-   BMI: Body Mass Index (Continuous)

-   Heart Rate: heart rate (Continuous)

-   Glucose: glucose level (Continuous)

    **Predict variable (desired target)**

-   10 year risk of coronary heart disease CHD (binary: "1", means "Yes", "0" means "No")

# Method

World Health Organization has estimated 12 million deaths occur worldwide, every year due to Heart diseases. Half the deaths in the United States and other developed countries are due to cardio vascular diseases. The early prognosis of cardiovascular diseases can aid in making decisions on lifestyle changes in high risk patients and in turn reduce the complications. This research intends to pinpoint the most relevant/risk factors of heart disease as well as predict the overall risk using logistic regression.

### Prepare environment / Load libraries

```{r}
library(haven)
library(tidyverse)
library(gtsummary)
library(broom)
library(knitr)
library(tidyr)
library(dplyr)
library(corrplot)
library(dagitty)
```

### Read data

```{r}
Data1 <- read_sav("framinghamTrue.sav")
```

### View Data

```{r}
summary(Data1)
str(Data1)
glimpse(Data1)
```

### Transform data

```{r}
Data2 <- Data1 %>%
  mutate(across(where(is.labelled), as_factor)) %>%
  mutate(glucose = as.integer(glucose))
summary(Data2)
```

### Describe Data

```{r}
Data2 %>%
  tbl_summary(by = TenYearCHD, statistic = list(all_continuous() ~ "{mean} ({sd})", all_categorical() ~ "{n} ({p}%)"))
```

### Explore data

#### Plots

Histogram for numerical Barplots for categorical

Numerical: Age, CigPerday, totchol, SBP, DBP, BMI, HR, glucose Categorical: Gender, Education, current smoker, BPmeds, PrevStroke, PrevHPt, DMstat, TenYearCHD

```{r}
Data2 %>% 
  ggplot(aes(age)) + 
  geom_histogram() + 
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>%
  ggplot(aes(cigsPerDay)) +
  geom_histogram() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>%
  ggplot(aes(totChol)) +
  geom_histogram() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>%
  ggplot(aes(sysBP)) +
  geom_histogram() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>%
  ggplot(aes(diaBP)) +
  geom_histogram() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>%
  ggplot(aes(BMI)) +
  geom_histogram() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>%
  ggplot(aes(heartRate)) +
  geom_histogram() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>%
  ggplot(aes(glucose)) +
  geom_histogram() +
  facet_grid(. ~ TenYearCHD)
```

Barplots

```{r}
Data2 %>% 
  ggplot(aes(gender)) + 
  geom_bar() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>% 
  ggplot(aes(education)) +  
  geom_bar() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>% 
  ggplot(aes(currentSmoker)) +  
  geom_bar() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>% 
  ggplot(aes(BPMeds)) +  
  geom_bar() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>% 
  ggplot(aes(prevalentStroke)) +  
  geom_bar() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>% 
  ggplot(aes(prevalentHyp)) +  
  geom_bar() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>% 
  ggplot(aes(diabetes)) +  
  geom_bar() +
  facet_grid(. ~ TenYearCHD)
```

```{r}
Data2 %>% 
  ggplot(aes(TenYearCHD)) +  
  geom_bar()
```

#### Check Multicollinearity

```{r}
Data3 <- 
  Data2 %>% 
  select(where(is.numeric))
```

```{r}
cor.Data3 <-
  cor(Data3, use = "complete.obs", method = "pearson")
head(round(cor.Data3,2))
```

```{r}
corrplot(cor.Data3, type = 'upper', order = 'hclust')
```

From the correlation plot and correlation matrix, sbp and dbp is highly correlated. Furthermore, the categorical variable of prevalent hypertension already represent the hypertension status. Hence, sbp and dbp are removed from model.

Similiarly, glucose is already representated by diabetes status.

#### Confounder and mediator

#### Causal diagram

```{r}
myDag <- dagitty(' dag {
bb="0,0,1,1"
"Anti-Hypertensive Medication" [pos="0.602,0.881"]
"Smoking Status" [pos="0.743,0.775"]
"Total Cholesterol" [pos="0.302,0.122"]
Age [pos="0.541,0.072"]
BMI [pos="0.700,0.190"]
CHD [outcome,pos="0.817,0.482"]
Diabetes [exposure,pos="0.092,0.449"]
Gender [pos="0.185,0.754"]
Hypertension [pos="0.359,0.897"]
"Anti-Hypertensive Medication" -> CHD
"Anti-Hypertensive Medication" <-> Hypertension
"Smoking Status" -> CHD
"Smoking Status" -> Hypertension
"Total Cholesterol" -> CHD
"Total Cholesterol" -> Hypertension
Age -> CHD
Age -> Diabetes
Age -> Hypertension
BMI -> "Total Cholesterol"
BMI -> CHD
BMI -> Hypertension
BMI <-> Diabetes
Diabetes -> "Total Cholesterol"
Diabetes -> CHD
Diabetes -> Hypertension
Gender -> "Smoking Status"
Gender -> "Total Cholesterol"
Gender -> CHD
Gender -> Diabetes
Gender -> Hypertension
Hypertension -> CHD
}')
plot(myDag)
```

From the causal diagram, the exposure studied is diabetes status(diabetes) and the outcome of interest is ten years risk of developing CHD(TenYearCHD)

We identified that variables Age (age), BMI (BMI), Gender(Gender) as confounder. Total cholesterol(totChol), hypertension(prevalentHyp) and antihypertensive medication(BPMeds) a s mediatorsfrom the causal diagram.

# Results

## Estimation

## Simple Logistic Regression

Outcome: Ten Year Risk Developing CHD

Based on literature review and expert consultation, these are the potential risk factors for developing Coronary heart disease in ten years

Numerical: Age, total chol, BMI, CigsPerday, sbp, dbp, glucose, HR Categorical: HPT, DM, gender, BP meds, prev stroke, current Smoking status, education

```{r}
#slr.all <- glm(TenYearCHD ~ 1, data = Data1, family = binomial(link = "logit"))
#add1(slr.all,scope = ~ age + totChol + BMI + cigsPerDay + sysBP + diaBP + heartRate + glucose + gender + education + prevalentHyp + prevalentStroke + currentSmoker + BPMeds + diabetes, test = "LRT")
```

#### ALL VARIABLES

```{r}
tbl_uvregression(Data2, method = glm, y = TenYearCHD, method.args = list(family = binomial), exponentiate = TRUE) #odd ratio
tbl_uvregression(Data2, method = glm, y = TenYearCHD, method.args = list(family = binomial)) # log odds
```

## Multiple Logistic Regression

### Model A: Model without interaction

Outcome: Ten Year risk of CHD

According to literature review, based on causal diagram and correlation matrix, these are the potential risk factors for developing CHD:

Numerical IV : age + totChol + BMI + cigsPerDay Categorical IV: gender + prevalentHyp + BPMeds + diabetes

```{r}
mlr.main <- glm(TenYearCHD ~ gender + age + cigsPerDay + prevalentHyp + diabetes + totChol + BMI + BPMeds, family = binomial(link="logit"), data = Data2)
summary(mlr.main)
tidy(mlr.main) # log odds
tidy(mlr.main, exponentiate = TRUE) # odds ratio
```

```{r}
tbl_regression(mlr.main) %>%
  add_n(location = "level") %>%
  bold_labels()%>%
  italicize_levels()
```

```{r}
tbl_regression(mlr.main, exponentiate = TRUE) %>%
  add_n(location = "level") %>%
  bold_labels()%>%
  italicize_levels()
```

### Model B: Model with interaction

Outcome: Ten Year risk of CHD

Numerical IV : age + totChol + BMI + cigsPerDay\
Categorical IV: gender + prevalentHyp + BPMeds + diabetes

Interaction: Total Cholesterol with Hypertension status

```{r}
mlr.ia <- glm(TenYearCHD ~ gender + age + cigsPerDay + prevalentHyp + diabetes + totChol + BMI + BPMeds + totChol:prevalentHyp, family = binomial(link="logit"), data = Data2)
summary(mlr.ia)
tidy(mlr.ia)
tidy(mlr.ia, exponentiate = TRUE)
```

### Model Selection

Model A vs Model B, need to compare with anova test

```{r}
anova(mlr.main, mlr.ia, test = 'Chisq')
```

From the ANOVA The p-value (Pr(\>Chi)) is greater than the typical significance level of 0.05. This suggests there is no difference between the two models.

Hence, we choose multivariable model A (mlr.main) as our preliminary Final Model for Logistic Regression due to model with the least variable is parsimonious model. Model A has the outcome (Ten Year CHD = chd/nochd) and the predictor of interest(diabetes) along with other covariates (gender, age, cigs per day, prevalent hypertension, total cholesterol, BMI and BP Medication status)

## Prediction

For prediction: 1. estimated log odds 2. probabilities 3. residuals 4.hat values 5. Cooks distance 6. standardized residuals

Now, our preliminary final model is (mlr.main)

```{r}
prem.final.mod <- mlr.main
prem.final.mod
```

### Log Odds

```{r}
tidy(prem.final.mod, conf.int = TRUE)
```

### Predicted Odds

```{r}
tidy(prem.final.mod, exponentiate = TRUE, conf.int = TRUE)
```

### Predict Probability

Formula for odds = probability / 1 - probability Formula for probability = Odds / 1 + Odds

```{r}
Prob.CHD <- augment(prem.final.mod, type.predict = 'response')  #To get probability, must include type.predict = 'response', if not, the fitted values will produce the log odds
Prob.CHD
```

```{r}
head(model.matrix(prem.final.mod))
```

```{r}
head(predict(prem.final.mod, type = 'link'))
```

```{r}
head(predict(prem.final.mod, type = 'response'))
```

Try to manually calculate:

Gender = 1 Age = 39 Cigs Perday = 0 HPT = 0 DM = 0 Totchol = 195 BMI = 26.97 BPmed = 0

Formula for log odds = B0 + B1X1 + B2X2 .......

Predicted log odds for first observation =

```{r}
(-7.1392+(0.4976*1)+(39*0.0719)+(0*0.0196)+(0*0.7249)+(195*0.0025)+(26.97*0.0152)+(0*0.3491))
```

Predicted odds:

Formula: exp(B0 + B1X1 + B2X2......)

```{r}
exp(-2.940056)
```

Manual calculation of predicted probability:

Formula for probability: Odds / 1 + Odds

```{r}
0.05286277/(1 + 0.05286277)
```

Another example: !!!! Try for 5th observation!!! Practice!!! (for own notes\*\*)

```{r}
augment(prem.final.mod, type.predict = 'response', type.residuals = 'pearson')
```

### Predict for new Data

```{r}
summary(model.matrix(prem.final.mod))
```

Make a predictions on new data

```{r}
newdata1 <- expand.grid(age = seq(from = 32, to = 70, by = 10),
                       totChol = seq(from = 113, to = 400, by = 50),
                       diabetes = c('no dm', 'dm'),
                       gender = c('male', 'female'),
                       cigsPerDay = seq(from = 0, to = 70),
                       prevalentHyp = c('hpt', 'no hpt'),
                       BMI = seq(from = 15.54, to = 56.80, by=10),
                       BPMeds = c('not on hypertensive medication', 'on hypertensive medication'),
                       TenYearCHD = c('no chd', 'chd'))
newdata1
head(newdata1)
```

```{r}
#model.mlr.new <- glm(TenYearCHD ~ gender + age + cigsPerDay + prevalentHyp + diabetes + totChol + BMI + BPMeds, family = binomial(link="logit"), data = newdata1)
#model.mlr.new
predict.logodds <- augment(prem.final.mod, newdata = newdata1, type.predict = 'link') #log odds
head(predict.logodds)
```

```{r}
predict.prob <- augment(prem.final.mod, newdata = newdata1, type.predict = 'response') # probability
head(predict.prob)
```

```{r}
augment(prem.final.mod, newdata = newdata1, type.predict = 'response')
```

## Model Checking

### Check overall fitness:

1.  Accuracy
2.  Sensitivity
3.  SPecificity

```{r}
prem.final.prob <- 
  augment(prem.final.mod, type.predict = 'response') %>%
  mutate(pred.class = factor(ifelse(.fitted > 0.5, 'chd', 'no chd')))
library(caret)
```

```{r}
confusionMatrix(prem.final.prob$TenYearCHD, prem.final.prob$pred.class)
```

The model has an overall accuracy of 85.07%, model able to predict correctly 85.07% of the cases.

Sensitivity (True Positive Rate) is relatively low at 65.71%, indicating that the model is not very good at capturing all positive cases.

Specificity (True Negative Rate) is higher at 85.25%, indicating good performance in correctly identifying negative cases.

### Linearity in logits

Numerical covariates should be checked for linearity in logits: age, totchol, BMI, cigs perday

```{r}
library(mfp)
```

```{r}
lin.numerical <- mfp(TenYearCHD ~ gender + fp(age) + fp(cigsPerDay) + prevalentHyp + diabetes + 
    fp(totChol) + fp(BMI) + BPMeds, family = binomial(link = 'logit'), data = Data2, verbose = T)
```

The transition from null modell to the linear model indicates the improvement in fit by adding the predictor variables. The final model deviance shows that the additional transformation by fractional polynomial does not lead to a significant improvement in fit.

### Checking Goodness of fit test

by using:

• area under the curve • Hosmer-Lemeshow test • modidied Hosmer-Lemeshow test • Oseo Rojek test

#### Hosmer-Lemeshow Test

Based on Mark Bounthavong, the hoslem.test function might cause the p-values to be very small if the outcome variable is analysed under factorized variable. Hence, Mark suggested to use several other function from other packages to perform Hosmer-lemeshow test.

Several suggestion R packages function includes:

1.hoslem.test function from the ResourceSelection package 2.performance_hosmer function from the performance package 3.hltest function from the largesamplehl package

largesamplehl package need to be installed using the below codes, as suggested by Mark Bounthavong.

```{r}
install_github("gnattino/largesamplehl")
```

```{r}
# Assuming 'model' is your logistic regression model
library("ResourceSelection")
library("largesamplehl")
library("PredictABEL")
library("performance")
hoslem.test(Data1$TenYearCHD, fitted(prem.final.mod), g = 10)
```

Based on hoslem.test function from Resource selection package, the model is statistically significant (p value \< 0.001) shows the model is not good fit.

```{r}
performance_hosmer(prem.final.mod, n_bins = 10)
```

However, another method to assess goodness of fit using other R packages: performance_hosmer function from the performance package, the model shows good fit of the data as the performance_hosmer GOF test (p value = 0.336)

```{r}
hltest(prem.final.mod, G = 10)
```

Similiarly, the modified Hosmer-Lemeshow test using the hltest function from the largesamplehl package, supported the model shows good fit to the data, p value = 0.3389

```{r}
library("rms")
```

#### Omnibus Goodness of Fit test

```{r}
prem.final.res <- lrm(TenYearCHD ~ age + BMI + totChol + cigsPerDay + prevalentHyp + diabetes + BPMeds + gender, data = Data2, y = TRUE, x = TRUE)
residuals(prem.final.res, type = "gof")
```

Based on the omnibus GOF test for preliminary final model (p value = 0.239), the model fit the data well.

#### Area under the Curve (ROC)

```{r}
library(pROC)
roc_curve <- roc(TenYearCHD ~ predict(prem.final.mod, type = "response"), data = Data2)
auc(roc_curve)
plot(roc_curve)

```

Area under Receiver of Operating Characteristic Curve (AUC-ROC):

AUC-ROC is 73.1%, the model is considered moderate discriminating effect.

Hence, all of above goodness of fit test shows that our model(prem.final.mod) has good fit.

### Diagnostic Plot

We can visualize any influential outliers from these diagnostic plots for preliminary final model (prem.final.mod).

```{r}
plot(prem.final.mod)
```

From the Pearson residual plots, we can identify there are influential outliers greater than +2

The studentized pearson residual plots, we can also noted there are outliers greater than +2, the leverage are higher than +2 suggests presence of influential outliers

These outliers observations may affect considerably our logistic regression model.

### Identify Influentials outliers

First, we need to identify influentials outliers, and we will attempt to remove those outliers and reperform the goodness of fit test for the filtered data.

One of the method to remove outliers is by setting the threshold for Cook's Distance deviations

```{r}

# Calculate influence measures
infl <- influence.measures(prem.final.mod)
infl.val <- data.frame(infl$infmat)

# Set a threshold for Cook's distance deviations
cutoff_value <- 4/3656

# Filter out influential observations
filtered_data <- Data2 |> filter(infl.val$cook.d <= cutoff_value)
```

Subsequently using the filtered data and fit into the logistic regression model, and this will be our adjusted model.

#### Adjusted Model

# Fit the logistic regression model again using the filtered data

```{r}
mlr.filtered.influential <- glm(TenYearCHD ~ gender + age + cigsPerDay + prevalentHyp + diabetes + totChol + BMI + BPMeds, family = binomial(link="logit"), data = filtered_data)
```

Next, we can assess the goodness of fit for the adjusted model with Hosmer-Lemeshow (HL) goodness of fit (GOF) test

### Reperform Model Checking for Adjusted Model

### Check overall fitness:

1.  Accuracy
2.  Sensitivity
3.  SPecificity

```{r}
mlr.filtered.prob <- 
  augment(mlr.filtered.influential, type.predict = 'response') %>%
  mutate(pred.class = factor(ifelse(.fitted > 0.5, 'chd', 'no chd')))
```

```{r}
confusionMatrix(mlr.filtered.prob$TenYearCHD, mlr.filtered.prob$pred.class)
```

The adjusted model shows an improvement in accuracy (91.77%) compared to the preliminary final model (85.07%).

Sensitivity in the adjusted model 58.33%, indicating the proportion of true positive cases correctly identified.

Specificity in the adjusted model is 92.00%, indicating the proportion of true negative cases correctly identified.

#### Checking linearity in logit

```{r}
lin.numerical <- mfp(TenYearCHD ~ gender + fp(age) + fp(cigsPerDay) + prevalentHyp + diabetes + 
    fp(totChol) + fp(BMI) + BPMeds, family = binomial(link = 'logit'), data = filtered_data, verbose = T)
```

The transition from null model (1919.26) to the linear model (1550.029) indicates the improvement in fit by adding the predictor variables. The final model deviance shows that the additional transformation by fractional polynomial lead to a significant improvement in fit (1471.412).

#### Hosmer-Lemeshow Test

```{r}
# Assuming 'model' is your logistic regression model
library(ResourceSelection)
hoslem.test(filtered_data$TenYearCHD, fitted(mlr.filtered.influential), g = 10) 
```

Based on hoslem.test function from Resource selection package, the model is statistically significant (p value \< 0.001) shows the model is not good fit.

```{r}
performance_hosmer(mlr.filtered.influential, n_bins = 10)
```

As for performance_hosmer function from the performance package, the model still show good fit of the data as the performance_hosmer GOF test (p value = 0.053)

```{r}
hltest(mlr.filtered.influential, G = 10)
```

Similiarly, the modified Hosmer-Lemeshow test using the hltest function from the largesamplehl package, supported the model considered good fit to the data, p value = 0.053.

#### Omnibus Goodness of fit test

```{r}
mlr.filtered.res <- lrm(TenYearCHD ~ age + BMI + totChol + cigsPerDay + prevalentHyp + diabetes + BPMeds + gender, data = filtered_data, y = TRUE, x = TRUE)
residuals(mlr.filtered.res, type = "gof")
```

Based on the omnibus GOF test for preliminary final model (p value = 0.007), the model does not fit the data well.

#### Area under the Curve (ROC)

```{r}
# Assuming 'model' is your logistic regression model
library(pROC)
roc_curve <- roc(TenYearCHD ~ predict(mlr.filtered.influential, type = "response"), data = filtered_data)
auc(roc_curve)
plot(roc_curve)
```

The adjusted model shows an improvement in accuracy (91.77%) compared to the preliminary final model (85.07%).

Sensitivity in the adjusted model is 58.33% compared to the preliminary final model (65.71%), indicating the proportion of true positive cases correctly identified. Specificity in the adjusted model is 92.00% compared to the preliminary final model (85.25%), indicating the proportion of true negative cases correctly identified.

The AUC value is relatively high (82.2%), indicating good discriminatory power.

However, the overall Hosmer-Lemeshow GOF test(p \<0.001) and Omnibus GOF test (p=0.007) shows lack of good fit, but HL GOF (binned version) (p = 0.053)and modified HL GOF test (p = 0.053) still shows model fits the data but close to significance level of 0.05.

We propose to present these two model (1) Model A (prem.final.mod) and (2) Adjusted model - (mlr.filtered,influentials) as our logistic regression model.

As the goal of our analysis to determine the relationship between outcome (TenYear CHD development) with predictor of interest (diabetes) with other covariates, based on literature review, overall HL GOF test, HL GOF test binned version, modified HL GOF is to determine whether the fitted model adequately describes the observed outcome experience of the data to estimate and inference the relationship between those mentioned variables. Hence, the preliminary final model that were tested for goodness of fit test is considered best logistic regression model.

Subsequently, as our goal of the analysis is to adequate and accurately predict the probability of cases to develop the outcome variable, our adjusted model for logistic regression model may be the best model for prediction, in view of the significant improvement of AUC (73.1% to 82,2%), the improvement of accuracy and specificity of the model which might maximize the predictive accuracy.

```{r}
# Compare model summaries
summary(mlr.filtered.influential)
summary(prem.final.mod)
```

Currently, we have two model: Model A (prem.final.mod), and Adjusted Model (mlr.filtered.influential). Model A has the outcome of Ten Years Risk of CHD (TenYearCHD = chd/nochd) and the predictor of interest is (diabetes) and other covariates based on Data2, Adjusted model has similiar outcome (Ten Year CHD) and predictor of interest(diabetes) and other covariates based on filtered data(outliers removed).

We can see the differences of coefficients estimates for each covariates towards outcome variables for the two model. For example the age variable

### Reperform Diagnostic plots

```{r}
plot(mlr.filtered.influential)
```

Most residuals appear to be falling within greater -/+ 2, lesser influentials observation.

# Interpretation

Model A - Preliminary final model Model B - Adjusted model

```{r}
ModelA <- prem.final.mod
tidy(ModelA, exponentiate = TRUE)
```

```{r}
ModelB <- mlr.filtered.influential
tidy(ModelB, exponentiate = TRUE, conf.int = TRUE)
```

```{r}
tbl_regression(ModelA, exponentiate = TRUE) %>%
  bold_labels() %>%
  italicize_levels() %>%
  as_gt() %>%
  gt::tab_header(title = "Table 3. Multiple Logistic Regression (Model A)")

tbl_regression(ModelB, exponentiate = TRUE) %>%
  bold_labels() %>%
  italicize_levels() %>%
  as_gt() %>%
  gt::tab_header(title = "Table 4. Multiple Logistic Regression (Model B)")
```

## Model Equation

Model A Equation: Ten Years risk of CHD = (0.0000175) + 1.94(gender) + 1.07(age) + 1.02(cigsperday) + 1.84(prevalentHyp) + 2.06(diabetes) + 1.00(totChol)

Model B Equation: Ten Years risk of CHD = (0.0000175) + 2.36(gender) + 1.14(age) + 1.02(cigsperday) + 2.12(prevalentHyp)

### Interpretation:

For MODEL A:

Gender, Age, Number of cigarette smoked per day, hypertension status, diabetes and total cholesterol have significant association to development of CHD.

1.  Men has 1.94 time the odds compared to women to develop CHD (95% CI=1.34,2.02, p value \<0.001) when adjusted to age, cigperday, hypertension status, diabetes and total cholesterol.
2.  Every 1 year increase of age, has 1.07 time the odds of developing CHD (95% CI= 1.06,1.09, p value \<0.001) when adjusted to gender, cigperday & hypertension status , diabetes and total cholesterol.
3.  Every 1 stick of cigarette per day, has 1.02 time the odds of developing CHD (95% CI=1.01,1.03, p value \<0.001) when adjusted to gender, age, hypertension status, diabetes and total cholesterol.
4.  Those who diagnosed with hypertension, has 1.84 time the odds of developing CHD (95% CI = 1.49,2.27, p value \<0.001) when adjusted to gender, age, diabetes, tot cholesterol &cigperday.
5.  BMI and on Hypertensive medications or not, are not statistically significant association to developing CHD after adjusted to all other variables.

For MODEL B:

Gender, Age, Number of cigarette smoked per day, hypertension status have significant association to development of CHD.

1.  Men has 2.36 time the odds compared to women to develop CHD (95% CI:1.75,3.19, p value \<0.001) when adjusted to age, cigperday, hypertension status.
2.  Every 1 year increase of age, has 1.14 time the odds of developing CHD (95% CI: 1.11,1.16, p value \<0.001) when adjusted to gender, cigperday & hypertension status.
3.  Every 1 stick of cigarette per day, has 1.02 time the odds of developing CHD (95% CI 1.01,1.03, p value \<0.001) when adjusted to gender, age, hypertension status
4.  Those who diagnosed with hypertension, has 2.12 time the odds of developing CHD (95% CI 1.60,2.80, p value \<0.001) when adjusted to gender, age, cigperday.
5.  Diabetes status, total cholesterol level, BMI and on Hypertensive medications or not, are not statistically significant association to developing CHD after adjusted to all other variables.
